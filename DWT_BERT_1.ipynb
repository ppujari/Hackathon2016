{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQR6T4oWoZad",
    "papermill": {
     "duration": 0.012003,
     "end_time": "2024-06-09T07:53:01.418137",
     "exception": false,
     "start_time": "2024-06-09T07:53:01.406134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "‚úÖ Extracts text from a PDF. \n",
    "‚úÖ Splits it into overlapping chunks. \n",
    "‚úÖ Uses a Hugging Face QA model.    \n",
    "‚úÖ Asks a question over each chunk.\n",
    "‚úÖ Returns the best answer based on confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dKK1nzl5oZaf",
    "papermill": {
     "duration": 8.790156,
     "end_time": "2024-06-09T07:53:10.21984",
     "exception": false,
     "start_time": "2024-06-09T07:53:01.429684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from transformers import pipeline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        return \"\\n\".join(\n",
    "            page.extract_text() for page in pdf.pages if page.extract_text()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load text from .txt file\n",
    "def load_text_from_file(txt_path):\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens=450\n",
    "model_name=\"deepset/roberta-base-squad2\"\n",
    "model_tokenizer=\"deepset/roberta-base-squad2\"\n",
    "#model_name=\"allenai/longformer-base-4096\",\n",
    "#model_tokenizer=\"allenai/longformer-base-4096\"\n",
    "pdf_path=\"CIV_1798.160.pdf\"\n",
    "txt_path=\"\"\n",
    "question = \"What are the main topics discussed in this document?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Chunk text into overlapping pieces\n",
    "def chunk_text(text, max_tokens=max_tokens, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + max_tokens, len(words))\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += max_tokens - overlap\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run QA model on each chunk\n",
    "def get_best_answer(chunks, question, model_name=model_name, tokenizer=model_tokenizer):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model_name, tokenizer=model_tokenizer)\n",
    "    best_answer = None\n",
    "    best_score = -math.inf\n",
    "\n",
    "    for i, context in enumerate(chunks):\n",
    "        try:\n",
    "            result = qa_pipeline(question=question, context=context)\n",
    "            print(f\"‚úÖ Chunk {i+1} ‚Üí Answer: {result['answer']} (score: {result['score']:.4f})\")\n",
    "            if result[\"score\"] > best_score:\n",
    "                best_score = result[\"score\"]\n",
    "                best_answer = result[\"answer\"]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping chunk {i+1}: {e}\")\n",
    "    \n",
    "    return best_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Run the whole flow\n",
    "def answer_question_from_pdf(pdf_path, question):\n",
    "    print(\"üîç Extracting text...\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    print(\"üß± Splitting into chunks...\")\n",
    "    chunks = chunk_text(text, max_tokens=max_tokens, overlap=50)\n",
    "    \n",
    "    print(f\"üí¨ Asking: {question}\")\n",
    "    answer = get_best_answer(chunks, question)\n",
    "    \n",
    "    print(f\"\\nüéØ Best Answer: {answer}\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracting text...\n",
      "üß± Splitting into chunks...\n",
      "üí¨ Asking: What are the main topics discussed in this document?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 1 ‚Üí Answer: promote and protect consumer privacy, educate children in the area of online privacy (score: 0.0003)\n",
      "‚úÖ Chunk 2 ‚Üí Answer: grant program (score: 0.0009)\n",
      "\n",
      "üéØ Best Answer: grant program\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'grant program'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîß Usage\n",
    "answer_question_from_pdf(pdf_path, question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exact Match (EM): 0.0\n",
      "‚úÖ F1 Score: 70.58823529411765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import evaluate\n",
    "\n",
    "# Load the SQuAD-style metric\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "# Reference and prediction\n",
    "references = [\"Contractor may terminate the agreement with 30 days' written notice.\"]\n",
    "predictions = [\"Either party may terminate with 30 days' notice.\"]\n",
    "\n",
    "# Format as expected by the metric\n",
    "formatted_predictions = [{\"prediction_text\": p, \"id\": str(i)} for i, p in enumerate(predictions)]\n",
    "formatted_references = [{\"answers\": {\"text\": [r], \"answer_start\": [0]}, \"id\": str(i)} for i, r in enumerate(references)]\n",
    "\n",
    "# Compute EM and F1\n",
    "results = squad_metric.compute(predictions=formatted_predictions, references=formatted_references)\n",
    "\n",
    "print(\"‚úÖ Exact Match (EM):\", results[\"exact_match\"])\n",
    "print(\"‚úÖ F1 Score:\", results[\"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4294430,
     "sourceId": 7388005,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5044393,
     "sourceId": 8461984,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 27214,
     "sourceId": 32506,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 49004,
     "sourceId": 58495,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 52774,
     "sourceId": 63300,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6235.795214,
   "end_time": "2024-06-09T09:36:54.551516",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-09T07:52:58.756302",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
