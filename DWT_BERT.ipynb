{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQR6T4oWoZad",
    "papermill": {
     "duration": 0.012003,
     "end_time": "2024-06-09T07:53:01.418137",
     "exception": false,
     "start_time": "2024-06-09T07:53:01.406134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "âœ… Extracts text from a PDF. \n",
    "âœ… Splits it into overlapping chunks. \n",
    "âœ… Uses a Hugging Face QA model \n",
    "âœ… Asks a question over each chunk. \n",
    "âœ… Returns the best answer based on confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dKK1nzl5oZaf",
    "papermill": {
     "duration": 8.790156,
     "end_time": "2024-06-09T07:53:10.21984",
     "exception": false,
     "start_time": "2024-06-09T07:53:01.429684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import os\n",
    "from transformers import AutoModel, AutoTokenizer, BertModel, BertTokenizer, BertConfig, pipeline\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "import pdfplumber\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save PDF text to a .txt file (LlamaIndex can read from files)\n",
    "def save_pdf_as_txt(pdf_path, txt_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "save_pdf_as_txt(\"CIV_1798.160.pdf\", \"./doc/pdf_text_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9JkgUFDtqdB3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Answer: begin administering the\n",
      "grant program\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load documents\n",
    "documents = SimpleDirectoryReader(\"./docs\").load_data()\n",
    "\n",
    "# Step 2: Setup Legal QA model and embeddings\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    #model=\"allenai/longformer-base-4096\",\n",
    "    #tokenizer=\"allenai/longformer-base-4096\"\n",
    "    model=\"atharvamundada99/bert-large-question-answering-finetuned-legal\",\n",
    "    tokenizer=\"atharvamundada99/bert-large-question-answering-finetuned-legal\",\n",
    ")\n",
    "\n",
    "# Load full text\n",
    "with open(\"doc/pdf_text_1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    context = f.read()\n",
    "\n",
    "question = \"What are the main topics discussed in the document?\"\n",
    "\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(\"ðŸ’¡ Answer:\", result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4294430,
     "sourceId": 7388005,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5044393,
     "sourceId": 8461984,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 27214,
     "sourceId": 32506,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 49004,
     "sourceId": 58495,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 52774,
     "sourceId": 63300,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6235.795214,
   "end_time": "2024-06-09T09:36:54.551516",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-09T07:52:58.756302",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
